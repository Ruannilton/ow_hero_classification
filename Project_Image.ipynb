{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathname = './heroes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepara lista de tags assumindo que os arquivos estao em pastas nomeadas\n",
    "def get_taglist(path=\"./heroes/\"):    \n",
    "    names = [x[0] for x in os.walk(path)]\n",
    "    names = [n[len(path):] for n in names]\n",
    "    names = [n for n in names if n ]\n",
    "    if \".ipynb_checkpoints\" in names:\n",
    "        names.remove(\".ipynb_checkpoints\")\n",
    "    if \"train\" in names:\n",
    "        names.remove(\"train\")\n",
    "    if \"valid\" in names:\n",
    "        names.remove(\"valid\")\n",
    "    if \"test\" in names:\n",
    "        names.remove(\"test\")\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = get_taglist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepara pastas de treino, validacao e teste\n",
    "def prepare_folders(path = \"./\"):\n",
    "    train_dir = os.path.join(path, 'train')\n",
    "    if not os.path.exists(train_dir):\n",
    "        print(f\" step1 creating {train_dir}\")\n",
    "        os.mkdir(train_dir)\n",
    "    valid_dir = os.path.join(path, 'valid')\n",
    "    if not os.path.exists(valid_dir):\n",
    "        print(f\" step1 creating {valid_dir}\")\n",
    "        os.mkdir(valid_dir)\n",
    "    test_dir = os.path.join(path, 'test')\n",
    "    if not os.path.exists(test_dir):\n",
    "        print(f\" step1 creating {test_dir}\")\n",
    "        os.mkdir(test_dir)\n",
    "    \n",
    "    named_train_dirs = {}\n",
    "    for tag in tags:\n",
    "        name = os.path.join(train_dir, tag)\n",
    "        print(name)\n",
    "        named_train_dirs[tag] = name\n",
    "        \n",
    "    for p in named_train_dirs:\n",
    "        if not os.path.exists(named_train_dirs[p]):\n",
    "            print(f\"creating {named_train_dirs[p]}\")\n",
    "            os.mkdir(named_train_dirs[p])    \n",
    "    \n",
    "    named_valid_dirs = {}\n",
    "    for tag in tags:\n",
    "        name = os.path.join(valid_dir, tag) \n",
    "        print(name)\n",
    "        named_valid_dirs[tag] = name\n",
    "        \n",
    "    for p in named_valid_dirs:\n",
    "        if not os.path.exists(named_valid_dirs[p]):\n",
    "            print(f\"creating {named_valid_dirs[p]}\")\n",
    "            os.mkdir(named_valid_dirs[p])\n",
    "        \n",
    "    named_test_dirs = {}\n",
    "    for tag in tags:\n",
    "        name = os.path.join(test_dir, tag) \n",
    "        print(name)\n",
    "        named_test_dirs[tag] = os.path.join(test_dir, tag)\n",
    "        \n",
    "        for p in named_test_dirs:\n",
    "            if not os.path.exists(named_test_dirs[p]):\n",
    "                print(f\"creating {named_test_dirs[p]}\")\n",
    "                os.mkdir(named_test_dirs[p])\n",
    "\n",
    "                \n",
    "    return (train_dir, valid_dir, test_dir, named_train_dirs, named_valid_dirs, named_test_dirs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = prepare_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, valid_dir, test_dir, named_train_dirs, named_valid_dirs, named_test_dirs = dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# copia os dados para pasta de treino\n",
    "for tag in tags:    \n",
    "    print(f\"In {tag}\")     \n",
    "    match = [f for f in os.listdir(pathname+f\"{tag}\") if f[0].isdigit()]    \n",
    "    train_fac = 0.5 \n",
    "    match_length = int(len(match)*train_fac)\n",
    "    print(match_length)\n",
    "    for i in range(match_length):\n",
    "        src = os.path.join(pathname+f\"{tag}\", match[i])\n",
    "        dst = os.path.join(named_train_dirs[tag], match[i])\n",
    "        print(f\"copying from {src} to {dst}\")\n",
    "        shutil.copyfile(src, dst)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#copia os dados para pasta de validacao\n",
    "for tag in tags:  \n",
    "    print(f\"In {tag}\")     \n",
    "    match = [f for f in os.listdir(pathname+f\"{tag}\") if f[0].isdigit()]   \n",
    "    train_fac = 0.5 \n",
    "    valid_fac = 0.3\n",
    "    train_length = int(len(match)*train_fac)\n",
    "    valid_length = train_length + int(len(match)*valid_fac)\n",
    "    for i in range(train_length, valid_length, 1):\n",
    "        src = os.path.join(pathname+f\"{tag}\", match[i])\n",
    "        dst = os.path.join(named_valid_dirs[tag], match[i])\n",
    "        print(f\"copying from {src} to {dst}\")\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#copia os dados para pasta de testes\n",
    "for tag in tags:\n",
    "    if tag != \".ipynb_checkpoints\":\n",
    "        print(f\"In {tag}\")     \n",
    "        match = [f for f in os.listdir(pathname+f\"{tag}\") if f[0].isdigit()] \n",
    "        train_fac = 0.5 \n",
    "        valid_fac = 0.3\n",
    "        test_fac  = 0.2        \n",
    "        train_length = int(len(match)*train_fac)\n",
    "        valid_length = train_length + int(len(match)*valid_fac)\n",
    "        test_length =  train_length + valid_length + int(len(match)*test_fac)        \n",
    "        for i in range(valid_length, len(match)):             \n",
    "            src = os.path.join(pathname+f\"{tag}\", match[i])\n",
    "            dst = os.path.join(named_test_dirs[tag], match[i])\n",
    "            print(f\"copying from {src} to {dst}\")\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuracoes para KerasImageDataGenerator\n",
    "DataGeneratorParams = {}\n",
    "DataGeneratorParams[\"rescale\"] = 1./255\n",
    "DataGeneratorParams[\"rotation_range\"] = 90\n",
    "DataGeneratorParams[\"width_shift_range\"] = 0.3\n",
    "DataGeneratorParams[\"height_shift_range\"] = 0.3\n",
    "DataGeneratorParams[\"shear_range\"] = 0.3\n",
    "DataGeneratorParams[\"zoom_range\"] = 0.3\n",
    "DataGeneratorParams[\"horizontal_flip\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "train_datagen = ImageDataGenerator(**DataGeneratorParams)\n",
    "#validation\n",
    "valid_datagen = ImageDataGenerator(**DataGeneratorParams)\n",
    "#test\n",
    "test_datagen = ImageDataGenerator(**DataGeneratorParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuracoes para datagen\n",
    "datagen = {}\n",
    "datagen[\"target_size\"] = (512,512)\n",
    "datagen[\"batch_size\"] = 10\n",
    "datagen[\"classes\"] = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,  **datagen)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir,**datagen)\n",
    "test_generator  = test_datagen.flow_from_directory(test_dir, **datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=64, \\\n",
    "                     kernel_size=(3,3), \\\n",
    "                     padding=\"same\", activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(Conv2D(filters=64, \\\n",
    "                     kernel_size=(3,3), \\\n",
    "                     padding=\"same\", activation=\"relu\")) \n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Conv2D(filters=128, \\\n",
    "                     kernel_size=(3,3), \\\n",
    "                     padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128, \\\n",
    "                     kernel_size=(3,3), \\\n",
    "                     padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Conv2D(filters=64, \\\n",
    "                     kernel_size=(5,5), \\\n",
    "                     padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64, \\\n",
    "                     kernel_size=(5,5), \\\n",
    "                     padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D())    \n",
    "       \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "physical_devices = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices:\n",
    "    for dev in physical_devices:\n",
    "        tensorflow.config.experimental.set_memory_growth(dev, True)  \n",
    "        \n",
    "dt = len(tensorflow.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \",dt )\n",
    "print(\"tf version: \",tensorflow.__version__)\n",
    "device = \"\"\n",
    "if dt < 1:\n",
    "    print(\"No GPU Available, reverting to cpu\")\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    device = \"gpu\"\n",
    "    \n",
    "print(f\"device: {device}, enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (512,512,3)\n",
    "NUM_CLASSES = 30\n",
    "model = build_network(INPUT_SHAPE, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tensorflow.device(f'/{device}:0'):\n",
    "    history = model.fit(train_generator, steps_per_epoch=25, epochs=500, validation_data=valid_generator, validation_steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc         = history.history[\"accuracy\"]\n",
    "val_acc     = history.history[\"val_accuracy\"]\n",
    "loss        = history.history[\"loss\"]\n",
    "val_loss    = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, label=\"training accuracy\")\n",
    "plt.plot(epochs, val_acc, label=\"validation accuracy\" )\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, label=\"training loss\")\n",
    "plt.plot(epochs, val_loss, label=\"validation loss\" )\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d46220209b51130533d6bdff8eec9e69741fb74c7757ec2fe0eb47c823723d93"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}